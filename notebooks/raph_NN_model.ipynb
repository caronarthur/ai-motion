{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "018267ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras import Sequential, layers\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers.experimental.preprocessing import Rescaling\n",
    "from tensorflow.keras import regularizers, Sequential, layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.constraints import unit_norm\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from tensorflow.keras.models import save_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b09e9d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../speech_emotion_reco/data/merged_dataset.csv')\n",
    "df_train = pd.read_csv('df_train.csv')\n",
    "df_test = pd.read_csv('df_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "cb42cf0d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>observation</th>\n",
       "      <th>path</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8105_stretch</td>\n",
       "      <td>../speech_emotion_reco/data/images_augmented/s...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11516_shift</td>\n",
       "      <td>../speech_emotion_reco/data/images_augmented/s...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8889_pitch</td>\n",
       "      <td>../speech_emotion_reco/data/images_augmented/p...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1741_shift</td>\n",
       "      <td>../speech_emotion_reco/data/images_augmented/s...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6984_pitch</td>\n",
       "      <td>../speech_emotion_reco/data/images_augmented/p...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    observation                                               path  emotion\n",
       "0  8105_stretch  ../speech_emotion_reco/data/images_augmented/s...        2\n",
       "1   11516_shift  ../speech_emotion_reco/data/images_augmented/s...        3\n",
       "2    8889_pitch  ../speech_emotion_reco/data/images_augmented/p...        4\n",
       "3    1741_shift  ../speech_emotion_reco/data/images_augmented/s...        2\n",
       "4    6984_pitch  ../speech_emotion_reco/data/images_augmented/p...        4"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "ea58a8bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    6735\n",
       "4    6729\n",
       "0    6713\n",
       "1    6654\n",
       "2    6644\n",
       "5    6570\n",
       "Name: emotion, dtype: int64"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.emotion.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "cfd833ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>gender</th>\n",
       "      <th>emotion</th>\n",
       "      <th>path</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>sad</td>\n",
       "      <td>../speech_emotion_reco/data/savee/JK_sa01.wav</td>\n",
       "      <td>4.511837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>sad</td>\n",
       "      <td>../speech_emotion_reco/data/savee/JK_sa15.wav</td>\n",
       "      <td>6.058730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>neutral</td>\n",
       "      <td>../speech_emotion_reco/data/savee/DC_n13.wav</td>\n",
       "      <td>2.788889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>surprise</td>\n",
       "      <td>../speech_emotion_reco/data/savee/DC_su09.wav</td>\n",
       "      <td>3.433968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>male</td>\n",
       "      <td>neutral</td>\n",
       "      <td>../speech_emotion_reco/data/savee/DC_n07.wav</td>\n",
       "      <td>4.051791</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 gender   emotion                                           path  \\\n",
       "0           0   male       sad  ../speech_emotion_reco/data/savee/JK_sa01.wav   \n",
       "1           1   male       sad  ../speech_emotion_reco/data/savee/JK_sa15.wav   \n",
       "2           2   male   neutral   ../speech_emotion_reco/data/savee/DC_n13.wav   \n",
       "3           3   male  surprise  ../speech_emotion_reco/data/savee/DC_su09.wav   \n",
       "4           4   male   neutral   ../speech_emotion_reco/data/savee/DC_n07.wav   \n",
       "\n",
       "   duration  \n",
       "0  4.511837  \n",
       "1  6.058730  \n",
       "2  2.788889  \n",
       "3  3.433968  \n",
       "4  4.051791  "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "f712f06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(images_path):\n",
    "    classes = {'happy': 0, \n",
    "          'sad': 1,\n",
    "          'fear': 2,\n",
    "          'disgust': 3,\n",
    "          'angry': 4,\n",
    "          'neutral': 5,\n",
    "          'surprise': 6,\n",
    "          'unknown': 7}\n",
    "    \n",
    "    imgs = []\n",
    "    labels = []\n",
    "    \n",
    "    for path in images_path:\n",
    "        index = int(path.replace('.png','').replace(data_path,'').split('_')[1])\n",
    "        image = Image.open(path).convert('RGB')\n",
    "        resized_image = image.resize((256,256))\n",
    "        imgs.append(np.array(resized_image))\n",
    "        labels.append(classes[df.loc[index, 'emotion']])\n",
    "\n",
    "    X = np.array(imgs)\n",
    "    y = to_categorical(np.array(labels), num_classes=6)\n",
    "    \n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "b90cada6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = load_data(df_test.path.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "2b3c101f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = load_data(df_train.path.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "ad93cc20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "39ea98d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model():\n",
    "    model = Sequential()\n",
    "    model.add(layers.Conv2D(120, kernel_size=11, activation=\"relu\", strides=4, input_shape=(256,256,3), kernel_initializer='he_normal', kernel_regularizer=regularizers.l2(l=0.01)))\n",
    "    model.add(layers.MaxPooling2D(3, strides=2))\n",
    "    model.add(layers.Conv2D(256, kernel_size=5, activation=\"relu\", strides=1,kernel_initializer='he_normal', kernel_regularizer=regularizers.l2(l=0.01)))\n",
    "    model.add(layers.MaxPooling2D(3, strides=2))\n",
    "    model.add(layers.Conv2D(384, kernel_size=3, activation=\"relu\", kernel_initializer='he_normal', kernel_regularizer=regularizers.l2(l=0.01)))\n",
    "    model.add(layers.MaxPooling2D(3, strides=2))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(2048, activation='relu',kernel_initializer='he_normal', kernel_regularizer=regularizers.l2(l=0.01)))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(2048, activation='relu',kernel_initializer='he_normal', kernel_regularizer=regularizers.l2(l=0.01)))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(6, activation='softmax'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "fd4bd3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():  \n",
    "    model = load_model()\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer = 'adam',\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "518bb860",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-01 17:48:36.223766: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "321/321 [==============================] - ETA: 0s - loss: 106.4909 - accuracy: 0.2533"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-01 17:53:01.223815: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "321/321 [==============================] - 287s 883ms/step - loss: 106.4909 - accuracy: 0.2533 - val_loss: 60.4799 - val_accuracy: 0.3422\n",
      "Epoch 2/100\n",
      "321/321 [==============================] - 296s 923ms/step - loss: 53.6832 - accuracy: 0.3494 - val_loss: 47.6900 - val_accuracy: 0.4139\n",
      "Epoch 3/100\n",
      "321/321 [==============================] - 308s 958ms/step - loss: 43.2046 - accuracy: 0.4126 - val_loss: 39.0452 - val_accuracy: 0.4485\n",
      "Epoch 4/100\n",
      "321/321 [==============================] - 343s 1s/step - loss: 35.5656 - accuracy: 0.4661 - val_loss: 32.3096 - val_accuracy: 0.5049\n",
      "Epoch 5/100\n",
      "321/321 [==============================] - 384s 1s/step - loss: 29.6924 - accuracy: 0.4964 - val_loss: 27.1156 - val_accuracy: 0.4981\n",
      "Epoch 6/100\n",
      "321/321 [==============================] - 362s 1s/step - loss: 24.9706 - accuracy: 0.5150 - val_loss: 22.8761 - val_accuracy: 0.5197\n",
      "Epoch 7/100\n",
      "321/321 [==============================] - 350s 1s/step - loss: 21.0813 - accuracy: 0.5312 - val_loss: 19.3427 - val_accuracy: 0.5336\n",
      "Epoch 8/100\n",
      "321/321 [==============================] - 339s 1s/step - loss: 17.8302 - accuracy: 0.5457 - val_loss: 16.3608 - val_accuracy: 0.5687\n",
      "Epoch 9/100\n",
      "321/321 [==============================] - 321s 1000ms/step - loss: 15.1117 - accuracy: 0.5630 - val_loss: 13.8925 - val_accuracy: 0.5646\n",
      "Epoch 10/100\n",
      "321/321 [==============================] - 309s 962ms/step - loss: 12.8510 - accuracy: 0.5705 - val_loss: 11.8032 - val_accuracy: 0.5670\n",
      "Epoch 11/100\n",
      "321/321 [==============================] - 314s 978ms/step - loss: 10.8991 - accuracy: 0.5781 - val_loss: 10.1433 - val_accuracy: 0.5290\n",
      "Epoch 12/100\n",
      "321/321 [==============================] - 336s 1s/step - loss: 9.2428 - accuracy: 0.5915 - val_loss: 8.5334 - val_accuracy: 0.5800\n",
      "Epoch 13/100\n",
      "321/321 [==============================] - 323s 1s/step - loss: 7.8637 - accuracy: 0.5992 - val_loss: 7.2310 - val_accuracy: 0.5956\n",
      "Epoch 14/100\n",
      "321/321 [==============================] - 318s 991ms/step - loss: 6.6971 - accuracy: 0.6000 - val_loss: 6.1793 - val_accuracy: 0.6041\n",
      "Epoch 15/100\n",
      "321/321 [==============================] - 319s 993ms/step - loss: 5.6961 - accuracy: 0.6149 - val_loss: 5.3412 - val_accuracy: 0.5746\n",
      "Epoch 16/100\n",
      "321/321 [==============================] - 326s 1s/step - loss: 4.8563 - accuracy: 0.6212 - val_loss: 4.5324 - val_accuracy: 0.6133\n",
      "Epoch 17/100\n",
      "321/321 [==============================] - 361s 1s/step - loss: 4.2794 - accuracy: 0.5924 - val_loss: 3.8980 - val_accuracy: 0.6123\n",
      "Epoch 18/100\n",
      "321/321 [==============================] - 358s 1s/step - loss: 3.6171 - accuracy: 0.6292 - val_loss: 3.3880 - val_accuracy: 0.6147\n",
      "Epoch 19/100\n",
      "321/321 [==============================] - 359s 1s/step - loss: 3.1279 - accuracy: 0.6294 - val_loss: 3.3427 - val_accuracy: 0.5179\n",
      "Epoch 20/100\n",
      "321/321 [==============================] - 359s 1s/step - loss: 2.7568 - accuracy: 0.6297 - val_loss: 2.5852 - val_accuracy: 0.6240\n",
      "Epoch 21/100\n",
      "321/321 [==============================] - 358s 1s/step - loss: 2.4188 - accuracy: 0.6382 - val_loss: 2.2986 - val_accuracy: 0.6263\n",
      "Epoch 22/100\n",
      "321/321 [==============================] - 356s 1s/step - loss: 2.1751 - accuracy: 0.6369 - val_loss: 2.1224 - val_accuracy: 0.6073\n",
      "Epoch 23/100\n",
      "321/321 [==============================] - 354s 1s/step - loss: 1.9742 - accuracy: 0.6344 - val_loss: 1.9778 - val_accuracy: 0.5995\n",
      "Epoch 24/100\n",
      "321/321 [==============================] - 355s 1s/step - loss: 1.8030 - accuracy: 0.6376 - val_loss: 1.7395 - val_accuracy: 0.6278\n",
      "Epoch 25/100\n",
      "321/321 [==============================] - 350s 1s/step - loss: 1.6581 - accuracy: 0.6427 - val_loss: 1.6995 - val_accuracy: 0.5985\n",
      "Epoch 26/100\n",
      "321/321 [==============================] - 352s 1s/step - loss: 1.5628 - accuracy: 0.6419 - val_loss: 1.5908 - val_accuracy: 0.5993\n",
      "Epoch 27/100\n",
      "321/321 [==============================] - 353s 1s/step - loss: 1.4789 - accuracy: 0.6471 - val_loss: 1.4948 - val_accuracy: 0.6264\n",
      "Epoch 28/100\n",
      "321/321 [==============================] - 348s 1s/step - loss: 1.4398 - accuracy: 0.6426 - val_loss: 1.3939 - val_accuracy: 0.6425\n",
      "Epoch 29/100\n",
      "321/321 [==============================] - 346s 1s/step - loss: 1.3679 - accuracy: 0.6494 - val_loss: 1.4234 - val_accuracy: 0.6171\n",
      "Epoch 30/100\n",
      "321/321 [==============================] - 346s 1s/step - loss: 1.3707 - accuracy: 0.6435 - val_loss: 1.4505 - val_accuracy: 0.6008\n",
      "Epoch 31/100\n",
      "321/321 [==============================] - 343s 1s/step - loss: 1.3240 - accuracy: 0.6442 - val_loss: 1.3253 - val_accuracy: 0.6367\n",
      "Epoch 32/100\n",
      "321/321 [==============================] - 343s 1s/step - loss: 1.3081 - accuracy: 0.6500 - val_loss: 1.2847 - val_accuracy: 0.6458\n",
      "Epoch 33/100\n",
      "321/321 [==============================] - 348s 1s/step - loss: 1.2813 - accuracy: 0.6554 - val_loss: 1.3129 - val_accuracy: 0.6427\n",
      "Epoch 34/100\n",
      "321/321 [==============================] - 342s 1s/step - loss: 1.2818 - accuracy: 0.6534 - val_loss: 1.3292 - val_accuracy: 0.6191\n",
      "Epoch 35/100\n",
      "321/321 [==============================] - 340s 1s/step - loss: 1.2793 - accuracy: 0.6517 - val_loss: 1.3078 - val_accuracy: 0.6334\n",
      "Epoch 36/100\n",
      "321/321 [==============================] - 342s 1s/step - loss: 1.2451 - accuracy: 0.6609 - val_loss: 1.3250 - val_accuracy: 0.6262\n",
      "Epoch 37/100\n",
      "321/321 [==============================] - 340s 1s/step - loss: 1.2448 - accuracy: 0.6541 - val_loss: 1.2572 - val_accuracy: 0.6449\n",
      "Epoch 38/100\n",
      "321/321 [==============================] - 341s 1s/step - loss: 1.2325 - accuracy: 0.6643 - val_loss: 1.3949 - val_accuracy: 0.5981\n",
      "Epoch 39/100\n",
      "321/321 [==============================] - 341s 1s/step - loss: 1.2477 - accuracy: 0.6535 - val_loss: 1.3208 - val_accuracy: 0.6243\n",
      "Epoch 40/100\n",
      "321/321 [==============================] - 341s 1s/step - loss: 1.2484 - accuracy: 0.6545 - val_loss: 1.3002 - val_accuracy: 0.6258\n",
      "Epoch 41/100\n",
      "321/321 [==============================] - 342s 1s/step - loss: 1.2291 - accuracy: 0.6583 - val_loss: 1.2760 - val_accuracy: 0.6313\n",
      "Epoch 42/100\n",
      "321/321 [==============================] - 342s 1s/step - loss: 1.2200 - accuracy: 0.6625 - val_loss: 1.2842 - val_accuracy: 0.6304\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "model = build_model()\n",
    "\n",
    "es = EarlyStopping(monitor='val_accuracy', mode='max', patience=10, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(X_train, y_train, \n",
    "                    validation_split=0.2,\n",
    "                    epochs=100, \n",
    "                    batch_size=100,\n",
    "                    callbacks=[es],\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "f828509b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "537/537 - 50s - loss: 1.2834 - accuracy: 0.6495\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(X_test, y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "ae75114b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../speech_emotion_reco/CNN_model/assets\n"
     ]
    }
   ],
   "source": [
    "save_model(\n",
    "    model, '../speech_emotion_reco/CNN_model', overwrite=True, include_optimizer=True, save_format=None,\n",
    "    signatures=None, options=None, save_traces=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "a58fa900",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = tf.keras.models.load_model('../speech_emotion_reco/CNN_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "7bc5bef5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-02 19:31:46.572153: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2021-09-02 19:32:24.194281: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "assert np.allclose(model.predict(X_test), loaded_model.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "1d391275",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-01 17:46:15.118404: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "537/537 - 41s - loss: 49.0360 - accuracy: 0.1657\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model_test.evaluate(X_test, y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "15f181fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "177c7366",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_mlp = pd.read_csv('../speech_emotion_reco/data/test_proba_raph.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "6fd68eca",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pred_mlp = pred_mlp.set_index('observation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "a4913851",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "classes = {'happy': 0, \n",
    "          'sad': 1,\n",
    "          'fear': 2,\n",
    "          'disgust': 3,\n",
    "          'angry': 4,\n",
    "          'neutral': 5,\n",
    "          'surprise': 6,\n",
    "          'unknown': 7}\n",
    "index = 0 \n",
    "for column in y_pred.T:\n",
    "    pred_mlp[list(classes.keys())[index] + \"_raph\"] = column\n",
    "    index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "83815e5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>observation</th>\n",
       "      <th>path</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0_original</td>\n",
       "      <td>../speech_emotion_reco/data/images_augmented/o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0_stretch</td>\n",
       "      <td>../speech_emotion_reco/data/images_augmented/s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10000_original</td>\n",
       "      <td>../speech_emotion_reco/data/images_augmented/o...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10000_pitch</td>\n",
       "      <td>../speech_emotion_reco/data/images_augmented/p...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10001_noise</td>\n",
       "      <td>../speech_emotion_reco/data/images_augmented/n...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17157</th>\n",
       "      <td>9999_shift</td>\n",
       "      <td>../speech_emotion_reco/data/images_augmented/s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17158</th>\n",
       "      <td>9999_stretch</td>\n",
       "      <td>../speech_emotion_reco/data/images_augmented/s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17159</th>\n",
       "      <td>999_pitch</td>\n",
       "      <td>../speech_emotion_reco/data/images_augmented/p...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17160</th>\n",
       "      <td>99_original</td>\n",
       "      <td>../speech_emotion_reco/data/images_augmented/o...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17161</th>\n",
       "      <td>9_pitch</td>\n",
       "      <td>../speech_emotion_reco/data/images_augmented/p...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17162 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          observation                                               path  \\\n",
       "0          0_original  ../speech_emotion_reco/data/images_augmented/o...   \n",
       "1           0_stretch  ../speech_emotion_reco/data/images_augmented/s...   \n",
       "2      10000_original  ../speech_emotion_reco/data/images_augmented/o...   \n",
       "3         10000_pitch  ../speech_emotion_reco/data/images_augmented/p...   \n",
       "4         10001_noise  ../speech_emotion_reco/data/images_augmented/n...   \n",
       "...               ...                                                ...   \n",
       "17157      9999_shift  ../speech_emotion_reco/data/images_augmented/s...   \n",
       "17158    9999_stretch  ../speech_emotion_reco/data/images_augmented/s...   \n",
       "17159       999_pitch  ../speech_emotion_reco/data/images_augmented/p...   \n",
       "17160     99_original  ../speech_emotion_reco/data/images_augmented/o...   \n",
       "17161         9_pitch  ../speech_emotion_reco/data/images_augmented/p...   \n",
       "\n",
       "       emotion  \n",
       "0            1  \n",
       "1            1  \n",
       "2            2  \n",
       "3            2  \n",
       "4            2  \n",
       "...        ...  \n",
       "17157        0  \n",
       "17158        0  \n",
       "17159        4  \n",
       "17160        2  \n",
       "17161        2  \n",
       "\n",
       "[17162 rows x 3 columns]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "6230aa28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>angry</th>\n",
       "      <th>disgust</th>\n",
       "      <th>fear</th>\n",
       "      <th>happy</th>\n",
       "      <th>neutral</th>\n",
       "      <th>sad</th>\n",
       "      <th>happy_raph</th>\n",
       "      <th>sad_raph</th>\n",
       "      <th>fear_raph</th>\n",
       "      <th>disgust_raph</th>\n",
       "      <th>angry_raph</th>\n",
       "      <th>neutral_raph</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>observation</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0_original</th>\n",
       "      <td>2.291376e-07</td>\n",
       "      <td>6.642547e-08</td>\n",
       "      <td>7.583450e-14</td>\n",
       "      <td>5.367126e-15</td>\n",
       "      <td>3.795053e-10</td>\n",
       "      <td>9.999998e-01</td>\n",
       "      <td>0.019691</td>\n",
       "      <td>0.232391</td>\n",
       "      <td>0.085794</td>\n",
       "      <td>0.227592</td>\n",
       "      <td>0.013517</td>\n",
       "      <td>0.421015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0_stretch</th>\n",
       "      <td>4.400612e-09</td>\n",
       "      <td>4.845263e-05</td>\n",
       "      <td>9.796351e-10</td>\n",
       "      <td>3.116841e-12</td>\n",
       "      <td>3.912250e-04</td>\n",
       "      <td>9.985856e-01</td>\n",
       "      <td>0.021747</td>\n",
       "      <td>0.272781</td>\n",
       "      <td>0.118796</td>\n",
       "      <td>0.243764</td>\n",
       "      <td>0.013249</td>\n",
       "      <td>0.329663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10000_original</th>\n",
       "      <td>3.302859e-02</td>\n",
       "      <td>1.601639e-02</td>\n",
       "      <td>9.463198e-01</td>\n",
       "      <td>2.838790e-03</td>\n",
       "      <td>1.154285e-02</td>\n",
       "      <td>5.747730e-03</td>\n",
       "      <td>0.052651</td>\n",
       "      <td>0.381382</td>\n",
       "      <td>0.312122</td>\n",
       "      <td>0.157792</td>\n",
       "      <td>0.007922</td>\n",
       "      <td>0.088132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10000_pitch</th>\n",
       "      <td>2.075523e-02</td>\n",
       "      <td>5.564900e-01</td>\n",
       "      <td>3.435738e-01</td>\n",
       "      <td>8.536743e-03</td>\n",
       "      <td>2.496596e-01</td>\n",
       "      <td>1.189899e-01</td>\n",
       "      <td>0.011009</td>\n",
       "      <td>0.635718</td>\n",
       "      <td>0.209856</td>\n",
       "      <td>0.098195</td>\n",
       "      <td>0.002626</td>\n",
       "      <td>0.042596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10001_noise</th>\n",
       "      <td>9.921627e-01</td>\n",
       "      <td>4.149681e-05</td>\n",
       "      <td>1.331815e-03</td>\n",
       "      <td>6.289357e-03</td>\n",
       "      <td>7.248833e-10</td>\n",
       "      <td>1.193373e-07</td>\n",
       "      <td>0.169900</td>\n",
       "      <td>0.032887</td>\n",
       "      <td>0.108354</td>\n",
       "      <td>0.237867</td>\n",
       "      <td>0.421930</td>\n",
       "      <td>0.029062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999_shift</th>\n",
       "      <td>7.964782e-06</td>\n",
       "      <td>1.432951e-08</td>\n",
       "      <td>4.564824e-06</td>\n",
       "      <td>9.999981e-01</td>\n",
       "      <td>1.777097e-09</td>\n",
       "      <td>8.359679e-09</td>\n",
       "      <td>0.492319</td>\n",
       "      <td>0.018659</td>\n",
       "      <td>0.053059</td>\n",
       "      <td>0.094926</td>\n",
       "      <td>0.229721</td>\n",
       "      <td>0.111317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999_stretch</th>\n",
       "      <td>1.456020e-04</td>\n",
       "      <td>1.721675e-08</td>\n",
       "      <td>4.429794e-06</td>\n",
       "      <td>9.999564e-01</td>\n",
       "      <td>1.235610e-07</td>\n",
       "      <td>2.388654e-09</td>\n",
       "      <td>0.656049</td>\n",
       "      <td>0.006694</td>\n",
       "      <td>0.048226</td>\n",
       "      <td>0.049586</td>\n",
       "      <td>0.223210</td>\n",
       "      <td>0.016233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999_pitch</th>\n",
       "      <td>1.319471e-06</td>\n",
       "      <td>2.036677e-10</td>\n",
       "      <td>7.433832e-04</td>\n",
       "      <td>9.999913e-01</td>\n",
       "      <td>7.801448e-15</td>\n",
       "      <td>2.210580e-13</td>\n",
       "      <td>0.260744</td>\n",
       "      <td>0.026404</td>\n",
       "      <td>0.087453</td>\n",
       "      <td>0.159874</td>\n",
       "      <td>0.459900</td>\n",
       "      <td>0.005625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99_original</th>\n",
       "      <td>1.530653e-08</td>\n",
       "      <td>5.598455e-16</td>\n",
       "      <td>9.963585e-01</td>\n",
       "      <td>6.827762e-01</td>\n",
       "      <td>1.345303e-23</td>\n",
       "      <td>5.355358e-22</td>\n",
       "      <td>0.106054</td>\n",
       "      <td>0.097956</td>\n",
       "      <td>0.621135</td>\n",
       "      <td>0.100990</td>\n",
       "      <td>0.050804</td>\n",
       "      <td>0.023061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9_pitch</th>\n",
       "      <td>5.748149e-16</td>\n",
       "      <td>6.537396e-21</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>7.404198e-15</td>\n",
       "      <td>1.727884e-18</td>\n",
       "      <td>7.408578e-20</td>\n",
       "      <td>0.074889</td>\n",
       "      <td>0.162744</td>\n",
       "      <td>0.475331</td>\n",
       "      <td>0.100442</td>\n",
       "      <td>0.156584</td>\n",
       "      <td>0.030010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17162 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       angry       disgust          fear         happy  \\\n",
       "observation                                                              \n",
       "0_original      2.291376e-07  6.642547e-08  7.583450e-14  5.367126e-15   \n",
       "0_stretch       4.400612e-09  4.845263e-05  9.796351e-10  3.116841e-12   \n",
       "10000_original  3.302859e-02  1.601639e-02  9.463198e-01  2.838790e-03   \n",
       "10000_pitch     2.075523e-02  5.564900e-01  3.435738e-01  8.536743e-03   \n",
       "10001_noise     9.921627e-01  4.149681e-05  1.331815e-03  6.289357e-03   \n",
       "...                      ...           ...           ...           ...   \n",
       "9999_shift      7.964782e-06  1.432951e-08  4.564824e-06  9.999981e-01   \n",
       "9999_stretch    1.456020e-04  1.721675e-08  4.429794e-06  9.999564e-01   \n",
       "999_pitch       1.319471e-06  2.036677e-10  7.433832e-04  9.999913e-01   \n",
       "99_original     1.530653e-08  5.598455e-16  9.963585e-01  6.827762e-01   \n",
       "9_pitch         5.748149e-16  6.537396e-21  1.000000e+00  7.404198e-15   \n",
       "\n",
       "                     neutral           sad  happy_raph  sad_raph  fear_raph  \\\n",
       "observation                                                                   \n",
       "0_original      3.795053e-10  9.999998e-01    0.019691  0.232391   0.085794   \n",
       "0_stretch       3.912250e-04  9.985856e-01    0.021747  0.272781   0.118796   \n",
       "10000_original  1.154285e-02  5.747730e-03    0.052651  0.381382   0.312122   \n",
       "10000_pitch     2.496596e-01  1.189899e-01    0.011009  0.635718   0.209856   \n",
       "10001_noise     7.248833e-10  1.193373e-07    0.169900  0.032887   0.108354   \n",
       "...                      ...           ...         ...       ...        ...   \n",
       "9999_shift      1.777097e-09  8.359679e-09    0.492319  0.018659   0.053059   \n",
       "9999_stretch    1.235610e-07  2.388654e-09    0.656049  0.006694   0.048226   \n",
       "999_pitch       7.801448e-15  2.210580e-13    0.260744  0.026404   0.087453   \n",
       "99_original     1.345303e-23  5.355358e-22    0.106054  0.097956   0.621135   \n",
       "9_pitch         1.727884e-18  7.408578e-20    0.074889  0.162744   0.475331   \n",
       "\n",
       "                disgust_raph  angry_raph  neutral_raph  \n",
       "observation                                             \n",
       "0_original          0.227592    0.013517      0.421015  \n",
       "0_stretch           0.243764    0.013249      0.329663  \n",
       "10000_original      0.157792    0.007922      0.088132  \n",
       "10000_pitch         0.098195    0.002626      0.042596  \n",
       "10001_noise         0.237867    0.421930      0.029062  \n",
       "...                      ...         ...           ...  \n",
       "9999_shift          0.094926    0.229721      0.111317  \n",
       "9999_stretch        0.049586    0.223210      0.016233  \n",
       "999_pitch           0.159874    0.459900      0.005625  \n",
       "99_original         0.100990    0.050804      0.023061  \n",
       "9_pitch             0.100442    0.156584      0.030010  \n",
       "\n",
       "[17162 rows x 12 columns]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "ee4f617d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_mlp.to_csv('test_combined_proba.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "610b5db7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/raphaelvoortman/code/caronarthur/speech_emotion_reco/notebooks\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "fd1bf26d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arthur-model.ipynb                      mateo_first_neural_network.ipynb\r\n",
      "Arthur_data_exploration_featuring.ipynb mateo_neural_network.ipynb\r\n",
      "Arthur_searching_model.ipynb            mateo_saving_spect_as_image.ipynb\r\n",
      "EDA.ipynb                               merged_dataset.csv\r\n",
      "Mateo_data_augmentation.ipynb           model.joblib\r\n",
      "Untitled.ipynb                          raph_NN_model.ipynb\r\n",
      "df_test                                 raph_data_merge.ipynb\r\n",
      "df_test.csv                             raph_first_DL_model_VGG16.ipynb\r\n",
      "df_train                                raph_transform_images_to_array.ipynb\r\n",
      "df_train.csv                            spec.png\r\n",
      "mateo_data_exploration.ipynb            test_combined_proba.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "866f5ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!open ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "3363971c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/raphaelvoortman/.pyenv/versions/3.8.6/envs/lewagon_tf/lib/python3.8/site-packages/sklearn/base.py:310: UserWarning: Trying to unpickle estimator LabelBinarizer from version 0.22 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "/Users/raphaelvoortman/.pyenv/versions/3.8.6/envs/lewagon_tf/lib/python3.8/site-packages/sklearn/base.py:310: UserWarning: Trying to unpickle estimator MLPClassifier from version 0.22 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "model_mateo = joblib.load('../speech_emotion_reco/data/model_mateo.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "84c0feee",
   "metadata": {},
   "outputs": [],
   "source": [
    "example = pd.read_csv('../speech_emotion_reco/data/exemple.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "f612b12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "example.drop(columns='labels', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "b996b864",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 1]])"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_mateo.predict(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20d2315",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
